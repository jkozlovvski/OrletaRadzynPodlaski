{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:22:40.359003455Z",
     "start_time": "2023-05-18T16:22:20.804081362Z"
    }
   },
   "outputs": [],
   "source": [
    "# biblioteki\n",
    "from src.dataclass import TextDataSet, ImageDataSet\n",
    "from transformers import ViTImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision.transforms import transforms, ToPILImage, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:22:40.424715643Z",
     "start_time": "2023-05-18T16:22:40.363869897Z"
    }
   },
   "outputs": [],
   "source": [
    "# ładowanie danych\n",
    "image_data_set = ImageDataSet('../datasets/train_set')\n",
    "ImageDataSet.use_rgb(image_data_set)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    image_data_set,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:32:32.033907534Z",
     "start_time": "2023-05-18T16:32:29.993183461Z"
    }
   },
   "outputs": [],
   "source": [
    "# model z hugingface\n",
    "extractor = ViTImageProcessor.from_pretrained(\"DunnBC22/dit-base-Business_Documents_Classified_v2\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"DunnBC22/dit-base-Business_Documents_Classified_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# zmiana głowicy\n",
    "model.classifier = torch.nn.Linear(in_features=model.classifier.in_features, out_features=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# zamrożenie parametrów\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:33:37.330887636Z",
     "start_time": "2023-05-18T16:33:37.264472316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10849/10849 [03:25<00:00, 52.72it/s]\n",
      "100%|██████████| 10849/10849 [01:58<00:00, 91.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = [torch.tensor(x[0]) for x in tqdm(image_data_set)]\n",
    "\n",
    "labels = [torch.zeros(21)[x[1]] for x in tqdm(image_data_set)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10849 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/10849 [00:00<2:37:23,  1.15it/s]\u001B[A\n",
      "  0%|          | 2/10849 [00:01<2:06:03,  1.43it/s]\u001B[A\n",
      "  0%|          | 3/10849 [00:02<1:57:36,  1.54it/s]\u001B[A\n",
      "  0%|          | 4/10849 [00:02<1:50:07,  1.64it/s]\u001B[A\n",
      "  0%|          | 5/10849 [00:03<1:44:49,  1.72it/s]\u001B[A\n",
      "  0%|          | 6/10849 [00:03<1:41:44,  1.78it/s]\u001B[A\n",
      "  0%|          | 7/10849 [00:04<1:37:39,  1.85it/s]\u001B[A\n",
      "  0%|          | 8/10849 [00:04<1:37:40,  1.85it/s]\u001B[A\n",
      "  0%|          | 9/10849 [00:05<1:36:40,  1.87it/s]\u001B[A\n",
      "  0%|          | 10/10849 [00:05<1:35:29,  1.89it/s]\u001B[A\n",
      "  0%|          | 11/10849 [00:06<1:35:07,  1.90it/s]\u001B[A\n",
      "  0%|          | 12/10849 [00:06<1:34:15,  1.92it/s]\u001B[A\n",
      "  0%|          | 13/10849 [00:07<1:35:24,  1.89it/s]\u001B[A\n",
      "  0%|          | 14/10849 [00:07<1:36:31,  1.87it/s]\u001B[A\n",
      "  0%|          | 15/10849 [00:08<1:35:50,  1.88it/s]\u001B[A\n",
      "  0%|          | 16/10849 [00:08<1:33:39,  1.93it/s]\u001B[A\n",
      "  0%|          | 17/10849 [00:09<1:33:49,  1.92it/s]\u001B[A\n",
      "  0%|          | 18/10849 [00:09<1:35:21,  1.89it/s]\u001B[A\n",
      "  0%|          | 19/10849 [00:10<1:35:10,  1.90it/s]\u001B[A\n",
      "  0%|          | 20/10849 [00:10<1:34:26,  1.91it/s]\u001B[A\n",
      "  0%|          | 21/10849 [00:11<1:34:28,  1.91it/s]\u001B[A\n",
      "  0%|          | 22/10849 [00:11<1:33:34,  1.93it/s]\u001B[A\n",
      "  0%|          | 23/10849 [00:12<1:33:18,  1.93it/s]\u001B[A\n",
      "  0%|          | 24/10849 [00:13<1:32:16,  1.96it/s]\u001B[A\n",
      "  0%|          | 25/10849 [00:13<1:32:24,  1.95it/s]\u001B[A\n",
      "  0%|          | 26/10849 [00:14<1:31:37,  1.97it/s]\u001B[A\n",
      "  0%|          | 27/10849 [00:14<1:31:50,  1.96it/s]\u001B[A\n",
      "  0%|          | 28/10849 [00:15<1:34:34,  1.91it/s]\u001B[A\n",
      "  0%|          | 29/10849 [00:15<1:34:49,  1.90it/s]\u001B[A\n",
      "  0%|          | 30/10849 [00:16<1:34:32,  1.91it/s]\u001B[A\n",
      "  0%|          | 31/10849 [00:16<1:32:57,  1.94it/s]\u001B[A\n",
      "  0%|          | 32/10849 [00:17<1:32:51,  1.94it/s]\u001B[A\n",
      "  0%|          | 33/10849 [00:18<2:01:35,  1.48it/s]\u001B[A\n",
      "  0%|          | 34/10849 [00:19<2:26:38,  1.23it/s]\u001B[A\n",
      "  0%|          | 35/10849 [00:19<2:10:58,  1.38it/s]\u001B[A\n",
      "  0%|          | 36/10849 [00:20<2:06:13,  1.43it/s]\u001B[A\n",
      "  0%|          | 37/10849 [00:21<2:01:32,  1.48it/s]\u001B[A\n",
      "  0%|          | 38/10849 [00:21<1:59:20,  1.51it/s]\u001B[A\n",
      "  0%|          | 39/10849 [00:22<1:56:36,  1.55it/s]\u001B[A\n",
      "  0%|          | 40/10849 [00:22<1:50:02,  1.64it/s]\u001B[A\n",
      "  0%|          | 41/10849 [00:23<1:47:46,  1.67it/s]\u001B[A\n",
      "  0%|          | 42/10849 [00:23<1:42:37,  1.76it/s]\u001B[A\n",
      "  0%|          | 43/10849 [00:24<1:42:53,  1.75it/s]\u001B[A\n",
      "  0%|          | 44/10849 [00:25<1:43:27,  1.74it/s]\u001B[A\n",
      "  0%|          | 45/10849 [00:25<1:45:48,  1.70it/s]\u001B[A\n",
      "  0%|          | 46/10849 [00:26<1:51:45,  1.61it/s]\u001B[A\n",
      "  0%|          | 47/10849 [00:26<1:47:23,  1.68it/s]\u001B[A\n",
      "  0%|          | 48/10849 [00:27<1:43:24,  1.74it/s]\u001B[A\n",
      "  0%|          | 49/10849 [00:28<1:41:25,  1.77it/s]\u001B[A\n",
      "  0%|          | 50/10849 [00:28<1:38:22,  1.83it/s]\u001B[A\n",
      "  0%|          | 51/10849 [00:29<1:36:20,  1.87it/s]\u001B[A\n",
      "  0%|          | 52/10849 [00:29<1:36:34,  1.86it/s]\u001B[A\n",
      "  0%|          | 53/10849 [00:30<1:35:33,  1.88it/s]\u001B[A\n",
      "  0%|          | 54/10849 [00:30<1:33:55,  1.92it/s]\u001B[A\n",
      "  1%|          | 55/10849 [00:31<1:33:38,  1.92it/s]\u001B[A\n",
      "  1%|          | 56/10849 [00:31<1:39:26,  1.81it/s]\u001B[A\n",
      "  1%|          | 57/10849 [00:32<1:37:16,  1.85it/s]\u001B[A\n",
      "  1%|          | 58/10849 [00:32<1:36:34,  1.86it/s]\u001B[A\n",
      "  1%|          | 59/10849 [00:33<1:34:47,  1.90it/s]\u001B[A\n",
      "  1%|          | 60/10849 [00:33<1:32:46,  1.94it/s]\u001B[A\n",
      "  1%|          | 61/10849 [00:34<1:32:10,  1.95it/s]\u001B[A\n",
      "  1%|          | 62/10849 [00:34<1:33:06,  1.93it/s]\u001B[A\n",
      "  1%|          | 63/10849 [00:35<1:33:22,  1.93it/s]\u001B[A\n",
      "  1%|          | 64/10849 [00:35<1:33:10,  1.93it/s]\u001B[A\n",
      "  1%|          | 65/10849 [00:36<1:32:52,  1.94it/s]\u001B[A\n",
      "  1%|          | 66/10849 [00:36<1:34:23,  1.90it/s]\u001B[A\n",
      "  1%|          | 67/10849 [00:37<1:34:15,  1.91it/s]\u001B[A\n",
      "  1%|          | 68/10849 [00:37<1:34:26,  1.90it/s]\u001B[A\n",
      "  1%|          | 69/10849 [00:38<1:33:19,  1.93it/s]\u001B[A\n",
      "  1%|          | 70/10849 [00:38<1:32:45,  1.94it/s]\u001B[A\n",
      "  1%|          | 71/10849 [00:39<1:32:46,  1.94it/s]\u001B[A\n",
      "  1%|          | 72/10849 [00:40<1:32:28,  1.94it/s]\u001B[A\n",
      "  1%|          | 73/10849 [00:40<1:30:51,  1.98it/s]\u001B[A\n",
      "  1%|          | 74/10849 [00:41<1:31:12,  1.97it/s]\u001B[A\n",
      "  1%|          | 75/10849 [00:41<1:31:15,  1.97it/s]\u001B[A\n",
      "  1%|          | 76/10849 [00:42<1:31:43,  1.96it/s]\u001B[A\n",
      "  1%|          | 77/10849 [00:42<1:31:56,  1.95it/s]\u001B[A\n",
      "  1%|          | 78/10849 [00:43<1:31:32,  1.96it/s]\u001B[A\n",
      "  1%|          | 79/10849 [00:43<1:31:55,  1.95it/s]\u001B[A\n",
      "  1%|          | 80/10849 [00:44<1:32:36,  1.94it/s]\u001B[A\n",
      "  1%|          | 81/10849 [00:44<1:33:05,  1.93it/s]\u001B[A\n",
      "  1%|          | 82/10849 [00:45<1:32:55,  1.93it/s]\u001B[A\n",
      "  1%|          | 83/10849 [00:45<1:32:46,  1.93it/s]\u001B[A\n",
      "  1%|          | 84/10849 [00:46<1:31:28,  1.96it/s]\u001B[A\n",
      "  1%|          | 85/10849 [00:46<1:31:21,  1.96it/s]\u001B[A\n",
      "  1%|          | 86/10849 [00:47<1:31:42,  1.96it/s]\u001B[A\n",
      "  1%|          | 87/10849 [00:47<1:31:10,  1.97it/s]\u001B[A\n",
      "  1%|          | 88/10849 [00:48<1:30:53,  1.97it/s]\u001B[A\n",
      "  1%|          | 89/10849 [00:48<1:31:58,  1.95it/s]\u001B[A\n",
      "  1%|          | 90/10849 [00:49<1:32:14,  1.94it/s]\u001B[A\n",
      "  1%|          | 91/10849 [00:49<1:32:17,  1.94it/s]\u001B[A\n",
      "  1%|          | 92/10849 [00:50<1:32:50,  1.93it/s]\u001B[A\n",
      "  1%|          | 93/10849 [00:50<1:32:56,  1.93it/s]\u001B[A\n",
      "  1%|          | 94/10849 [00:51<1:33:26,  1.92it/s]\u001B[A\n",
      "  1%|          | 95/10849 [00:51<1:33:15,  1.92it/s]\u001B[A\n",
      "  1%|          | 96/10849 [00:52<1:31:30,  1.96it/s]\u001B[A\n",
      "  1%|          | 97/10849 [00:52<1:31:44,  1.95it/s]\u001B[A\n",
      "  1%|          | 98/10849 [00:53<1:30:42,  1.98it/s]\u001B[A\n",
      "  1%|          | 99/10849 [00:53<1:31:39,  1.95it/s]\u001B[A\n",
      "  1%|          | 100/10849 [00:54<1:30:48,  1.97it/s]\u001B[A\n",
      "  1%|          | 101/10849 [00:54<1:31:11,  1.96it/s]\u001B[A\n",
      "  1%|          | 102/10849 [00:55<1:30:44,  1.97it/s]\u001B[A\n",
      "  1%|          | 103/10849 [00:55<1:31:27,  1.96it/s]\u001B[A\n",
      "  1%|          | 104/10849 [00:56<1:31:44,  1.95it/s]\u001B[A\n",
      "  1%|          | 105/10849 [00:56<1:31:46,  1.95it/s]\u001B[A\n",
      "  1%|          | 106/10849 [00:57<1:32:03,  1.95it/s]\u001B[A\n",
      "  1%|          | 107/10849 [00:57<1:32:21,  1.94it/s]\u001B[A\n",
      "  1%|          | 108/10849 [00:58<1:33:19,  1.92it/s]\u001B[A\n",
      "  1%|          | 109/10849 [00:58<1:32:23,  1.94it/s]\u001B[A\n",
      "  1%|          | 110/10849 [00:59<1:32:38,  1.93it/s]\u001B[A\n",
      "  1%|          | 111/10849 [00:59<1:30:43,  1.97it/s]\u001B[A\n",
      "  1%|          | 112/10849 [01:00<1:33:54,  1.91it/s]\u001B[A\n",
      "  1%|          | 113/10849 [01:01<1:38:54,  1.81it/s]\u001B[A\n",
      "  1%|          | 114/10849 [01:01<1:38:35,  1.81it/s]\u001B[A\n",
      "  1%|          | 115/10849 [01:02<1:37:14,  1.84it/s]\u001B[A\n",
      "  1%|          | 116/10849 [01:02<1:36:42,  1.85it/s]\u001B[A\n",
      "  1%|          | 117/10849 [01:03<1:34:41,  1.89it/s]\u001B[A\n",
      "  1%|          | 118/10849 [01:03<1:33:41,  1.91it/s]\u001B[A\n",
      "  1%|          | 119/10849 [01:04<1:34:36,  1.89it/s]\u001B[A\n",
      "  1%|          | 120/10849 [01:04<1:34:06,  1.90it/s]\u001B[A\n",
      "  1%|          | 121/10849 [01:05<1:35:41,  1.87it/s]\u001B[A\n",
      "  1%|          | 122/10849 [01:05<1:35:43,  1.87it/s]\u001B[A\n",
      "  1%|          | 123/10849 [01:06<1:44:48,  1.71it/s]\u001B[A\n",
      "  1%|          | 124/10849 [01:07<1:42:28,  1.74it/s]\u001B[A\n",
      "  1%|          | 125/10849 [01:07<1:42:40,  1.74it/s]\u001B[A\n",
      "  1%|          | 126/10849 [01:08<1:38:56,  1.81it/s]\u001B[A\n",
      "  1%|          | 127/10849 [01:08<1:36:16,  1.86it/s]\u001B[A\n",
      "  1%|          | 128/10849 [01:09<1:34:52,  1.88it/s]\u001B[A\n",
      "  1%|          | 129/10849 [01:09<1:34:16,  1.90it/s]\u001B[A\n",
      "  1%|          | 130/10849 [01:10<1:38:41,  1.81it/s]\u001B[A\n",
      "  1%|          | 131/10849 [01:11<1:40:44,  1.77it/s]\u001B[A\n",
      "  1%|          | 132/10849 [01:11<1:41:51,  1.75it/s]\u001B[A\n",
      "  1%|          | 133/10849 [01:12<1:40:58,  1.77it/s]\u001B[A\n",
      "  1%|          | 134/10849 [01:12<1:38:00,  1.82it/s]\u001B[A\n",
      "  1%|          | 135/10849 [01:13<1:36:56,  1.84it/s]\u001B[A\n",
      "  1%|▏         | 136/10849 [01:13<1:36:59,  1.84it/s]\u001B[A\n",
      "  1%|▏         | 137/10849 [01:14<1:34:59,  1.88it/s]\u001B[A\n",
      "  1%|▏         | 138/10849 [01:14<1:34:29,  1.89it/s]\u001B[A\n",
      "  1%|▏         | 139/10849 [01:15<1:36:17,  1.85it/s]\u001B[A\n",
      "  1%|▏         | 140/10849 [01:15<1:37:24,  1.83it/s]\u001B[A\n",
      "  1%|▏         | 141/10849 [01:16<1:35:32,  1.87it/s]\u001B[A\n",
      "  1%|▏         | 142/10849 [01:16<1:35:08,  1.88it/s]\u001B[A\n",
      "  1%|▏         | 143/10849 [01:17<1:35:39,  1.87it/s]\u001B[A\n",
      "  1%|▏         | 144/10849 [01:18<1:42:20,  1.74it/s]\u001B[A\n",
      "  1%|▏         | 145/10849 [01:18<1:53:16,  1.57it/s]\u001B[A\n",
      "  1%|▏         | 146/10849 [01:19<1:57:29,  1.52it/s]\u001B[A\n",
      "  1%|▏         | 147/10849 [01:20<1:51:49,  1.59it/s]\u001B[A\n",
      "  1%|▏         | 148/10849 [01:20<1:50:00,  1.62it/s]\u001B[A\n",
      "  1%|▏         | 149/10849 [01:21<1:44:13,  1.71it/s]\u001B[A\n",
      "  1%|▏         | 150/10849 [01:21<1:40:33,  1.77it/s]\u001B[A\n",
      "  1%|▏         | 151/10849 [01:22<1:36:22,  1.85it/s]\u001B[A\n",
      "  1%|▏         | 152/10849 [01:22<1:38:38,  1.81it/s]\u001B[A\n",
      "  1%|▏         | 153/10849 [01:23<1:37:42,  1.82it/s]\u001B[A\n",
      "  1%|▏         | 154/10849 [01:23<1:38:32,  1.81it/s]\u001B[A\n",
      "  1%|▏         | 155/10849 [01:24<1:36:50,  1.84it/s]\u001B[A\n",
      "  1%|▏         | 156/10849 [01:24<1:35:05,  1.87it/s]\u001B[A\n",
      "  1%|▏         | 157/10849 [01:25<1:34:15,  1.89it/s]\u001B[A\n",
      "  1%|▏         | 158/10849 [01:26<1:33:49,  1.90it/s]\u001B[A\n",
      "  1%|▏         | 159/10849 [01:26<1:36:33,  1.85it/s]\u001B[A\n",
      "  1%|▏         | 160/10849 [01:27<1:35:08,  1.87it/s]\u001B[A\n",
      "  1%|▏         | 161/10849 [01:27<1:34:29,  1.89it/s]\u001B[A\n",
      "  1%|▏         | 162/10849 [01:28<1:32:28,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 163/10849 [01:28<1:31:01,  1.96it/s]\u001B[A\n",
      "  2%|▏         | 164/10849 [01:29<1:32:20,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 165/10849 [01:29<1:32:31,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 166/10849 [01:30<1:32:06,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 167/10849 [01:30<1:32:10,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 168/10849 [01:31<1:33:24,  1.91it/s]\u001B[A\n",
      "  2%|▏         | 169/10849 [01:31<1:32:20,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 170/10849 [01:32<1:32:33,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 171/10849 [01:32<1:32:04,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 172/10849 [01:33<1:30:26,  1.97it/s]\u001B[A\n",
      "  2%|▏         | 173/10849 [01:33<1:31:04,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 174/10849 [01:34<1:31:23,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 175/10849 [01:34<1:31:11,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 176/10849 [01:35<1:31:15,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 177/10849 [01:35<1:31:43,  1.94it/s]\u001B[A\n",
      "  2%|▏         | 178/10849 [01:36<1:32:47,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 179/10849 [01:36<1:34:46,  1.88it/s]\u001B[A\n",
      "  2%|▏         | 180/10849 [01:37<1:34:11,  1.89it/s]\u001B[A\n",
      "  2%|▏         | 181/10849 [01:38<1:34:56,  1.87it/s]\u001B[A\n",
      "  2%|▏         | 182/10849 [01:38<1:34:30,  1.88it/s]\u001B[A\n",
      "  2%|▏         | 183/10849 [01:39<1:35:54,  1.85it/s]\u001B[A\n",
      "  2%|▏         | 184/10849 [01:39<1:36:53,  1.83it/s]\u001B[A\n",
      "  2%|▏         | 185/10849 [01:40<1:37:43,  1.82it/s]\u001B[A\n",
      "  2%|▏         | 186/10849 [01:40<1:37:30,  1.82it/s]\u001B[A\n",
      "  2%|▏         | 187/10849 [01:41<1:38:19,  1.81it/s]\u001B[A\n",
      "  2%|▏         | 188/10849 [01:41<1:41:35,  1.75it/s]\u001B[A\n",
      "  2%|▏         | 189/10849 [01:42<1:38:36,  1.80it/s]\u001B[A\n",
      "  2%|▏         | 190/10849 [01:43<1:36:44,  1.84it/s]\u001B[A\n",
      "  2%|▏         | 191/10849 [01:43<1:34:08,  1.89it/s]\u001B[A\n",
      "  2%|▏         | 192/10849 [01:44<1:33:23,  1.90it/s]\u001B[A\n",
      "  2%|▏         | 193/10849 [01:44<1:32:19,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 194/10849 [01:45<1:31:25,  1.94it/s]\u001B[A\n",
      "  2%|▏         | 195/10849 [01:45<1:32:38,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 196/10849 [01:46<1:32:19,  1.92it/s]\u001B[A\n",
      "  2%|▏         | 197/10849 [01:46<1:30:56,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 198/10849 [01:47<1:28:56,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 199/10849 [01:47<1:28:05,  2.02it/s]\u001B[A\n",
      "  2%|▏         | 200/10849 [01:48<1:28:38,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 201/10849 [01:48<1:28:36,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 202/10849 [01:49<1:29:04,  1.99it/s]\u001B[A\n",
      "  2%|▏         | 203/10849 [01:49<1:29:32,  1.98it/s]\u001B[A\n",
      "  2%|▏         | 204/10849 [01:50<1:34:30,  1.88it/s]\u001B[A\n",
      "  2%|▏         | 205/10849 [01:50<1:32:54,  1.91it/s]\u001B[A\n",
      "  2%|▏         | 206/10849 [01:51<1:36:16,  1.84it/s]\u001B[A\n",
      "  2%|▏         | 207/10849 [01:51<1:35:38,  1.85it/s]\u001B[A\n",
      "  2%|▏         | 208/10849 [01:52<1:33:19,  1.90it/s]\u001B[A\n",
      "  2%|▏         | 209/10849 [01:52<1:32:36,  1.91it/s]\u001B[A\n",
      "  2%|▏         | 210/10849 [01:53<1:34:40,  1.87it/s]\u001B[A\n",
      "  2%|▏         | 211/10849 [01:53<1:35:27,  1.86it/s]\u001B[A\n",
      "  2%|▏         | 212/10849 [01:54<1:33:11,  1.90it/s]\u001B[A\n",
      "  2%|▏         | 213/10849 [01:54<1:31:14,  1.94it/s]\u001B[A\n",
      "  2%|▏         | 214/10849 [01:55<1:29:10,  1.99it/s]\u001B[A\n",
      "  2%|▏         | 215/10849 [01:55<1:29:22,  1.98it/s]\u001B[A\n",
      "  2%|▏         | 216/10849 [01:56<1:29:17,  1.98it/s]\u001B[A\n",
      "  2%|▏         | 217/10849 [01:56<1:28:58,  1.99it/s]\u001B[A\n",
      "  2%|▏         | 218/10849 [01:57<1:35:13,  1.86it/s]\u001B[A\n",
      "  2%|▏         | 219/10849 [01:57<1:33:45,  1.89it/s]\u001B[A\n",
      "  2%|▏         | 220/10849 [01:58<1:30:33,  1.96it/s]\u001B[A\n",
      "  2%|▏         | 221/10849 [01:58<1:29:53,  1.97it/s]\u001B[A\n",
      "  2%|▏         | 222/10849 [01:59<1:31:36,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 223/10849 [02:00<1:31:54,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 224/10849 [02:00<1:30:44,  1.95it/s]\u001B[A\n",
      "  2%|▏         | 225/10849 [02:01<1:30:10,  1.96it/s]\u001B[A\n",
      "  2%|▏         | 226/10849 [02:01<1:30:07,  1.96it/s]\u001B[A\n",
      "  2%|▏         | 227/10849 [02:02<1:29:44,  1.97it/s]\u001B[A\n",
      "  2%|▏         | 228/10849 [02:02<1:28:21,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 229/10849 [02:03<1:28:36,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 230/10849 [02:03<1:28:05,  2.01it/s]\u001B[A\n",
      "  2%|▏         | 231/10849 [02:04<1:28:21,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 232/10849 [02:04<1:31:34,  1.93it/s]\u001B[A\n",
      "  2%|▏         | 233/10849 [02:05<1:29:34,  1.98it/s]\u001B[A\n",
      "  2%|▏         | 234/10849 [02:05<1:28:42,  1.99it/s]\u001B[A\n",
      "  2%|▏         | 235/10849 [02:06<1:27:55,  2.01it/s]\u001B[A\n",
      "  2%|▏         | 236/10849 [02:06<1:28:07,  2.01it/s]\u001B[A\n",
      "  2%|▏         | 237/10849 [02:07<1:28:32,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 238/10849 [02:07<1:27:07,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 239/10849 [02:07<1:26:36,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 240/10849 [02:08<1:26:17,  2.05it/s]\u001B[A\n",
      "  2%|▏         | 241/10849 [02:09<1:28:36,  2.00it/s]\u001B[A\n",
      "  2%|▏         | 242/10849 [02:09<1:28:10,  2.01it/s]\u001B[A\n",
      "  2%|▏         | 243/10849 [02:09<1:27:13,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 244/10849 [02:10<1:27:24,  2.02it/s]\u001B[A\n",
      "  2%|▏         | 245/10849 [02:10<1:27:15,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 246/10849 [02:11<1:27:09,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 247/10849 [02:11<1:26:33,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 248/10849 [02:12<1:25:26,  2.07it/s]\u001B[A\n",
      "  2%|▏         | 249/10849 [02:12<1:26:15,  2.05it/s]\u001B[A\n",
      "  2%|▏         | 250/10849 [02:13<1:26:42,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 251/10849 [02:13<1:26:01,  2.05it/s]\u001B[A\n",
      "  2%|▏         | 252/10849 [02:14<1:25:22,  2.07it/s]\u001B[A\n",
      "  2%|▏         | 253/10849 [02:14<1:26:02,  2.05it/s]\u001B[A\n",
      "  2%|▏         | 254/10849 [02:15<1:27:11,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 255/10849 [02:15<1:26:42,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 256/10849 [02:16<1:27:26,  2.02it/s]\u001B[A\n",
      "  2%|▏         | 257/10849 [02:16<1:27:02,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 258/10849 [02:17<1:26:14,  2.05it/s]\u001B[A\n",
      "  2%|▏         | 259/10849 [02:17<1:25:08,  2.07it/s]\u001B[A\n",
      "  2%|▏         | 260/10849 [02:18<1:25:44,  2.06it/s]\u001B[A\n",
      "  2%|▏         | 261/10849 [02:18<1:27:36,  2.01it/s]\u001B[A\n",
      "  2%|▏         | 262/10849 [02:19<1:26:33,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 263/10849 [02:19<1:27:03,  2.03it/s]\u001B[A\n",
      "  2%|▏         | 264/10849 [02:20<1:27:07,  2.02it/s]\u001B[A\n",
      "  2%|▏         | 265/10849 [02:20<1:25:26,  2.06it/s]\u001B[A\n",
      "  2%|▏         | 266/10849 [02:21<1:26:24,  2.04it/s]\u001B[A\n",
      "  2%|▏         | 267/10849 [02:21<1:27:28,  2.02it/s]\u001B[A\n",
      "  2%|▏         | 268/10849 [02:22<1:30:03,  1.96it/s]\u001B[A\n",
      "  2%|▏         | 269/10849 [02:22<1:29:13,  1.98it/s]\u001B[A\n",
      "  2%|▏         | 270/10849 [02:23<1:34:46,  1.86it/s]\u001B[A\n",
      "  2%|▏         | 271/10849 [02:23<1:37:26,  1.81it/s]\u001B[A\n",
      "  3%|▎         | 272/10849 [02:24<1:36:45,  1.82it/s]\u001B[A\n",
      "  3%|▎         | 273/10849 [02:25<1:33:11,  1.89it/s]\u001B[A\n",
      "  3%|▎         | 274/10849 [02:25<1:32:40,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 275/10849 [02:26<1:34:44,  1.86it/s]\u001B[A\n",
      "  3%|▎         | 276/10849 [02:27<2:35:32,  1.13it/s]\u001B[A\n",
      "  3%|▎         | 277/10849 [02:28<2:24:07,  1.22it/s]\u001B[A\n",
      "  3%|▎         | 278/10849 [02:28<2:09:06,  1.36it/s]\u001B[A\n",
      "  3%|▎         | 279/10849 [02:29<1:56:44,  1.51it/s]\u001B[A\n",
      "  3%|▎         | 280/10849 [02:29<1:47:21,  1.64it/s]\u001B[A\n",
      "  3%|▎         | 281/10849 [02:30<1:47:48,  1.63it/s]\u001B[A\n",
      "  3%|▎         | 282/10849 [02:31<1:40:58,  1.74it/s]\u001B[A\n",
      "  3%|▎         | 283/10849 [02:31<1:37:04,  1.81it/s]\u001B[A\n",
      "  3%|▎         | 284/10849 [02:32<1:32:30,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 285/10849 [02:32<1:31:09,  1.93it/s]\u001B[A\n",
      "  3%|▎         | 286/10849 [02:33<1:29:03,  1.98it/s]\u001B[A\n",
      "  3%|▎         | 287/10849 [02:33<1:28:28,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 288/10849 [02:33<1:27:06,  2.02it/s]\u001B[A\n",
      "  3%|▎         | 289/10849 [02:34<1:27:25,  2.01it/s]\u001B[A\n",
      "  3%|▎         | 290/10849 [02:35<1:29:19,  1.97it/s]\u001B[A\n",
      "  3%|▎         | 291/10849 [02:35<1:30:46,  1.94it/s]\u001B[A\n",
      "  3%|▎         | 292/10849 [02:36<1:31:27,  1.92it/s]\u001B[A\n",
      "  3%|▎         | 293/10849 [02:36<1:32:02,  1.91it/s]\u001B[A\n",
      "  3%|▎         | 294/10849 [02:37<1:31:48,  1.92it/s]\u001B[A\n",
      "  3%|▎         | 295/10849 [02:37<1:32:45,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 296/10849 [02:38<1:32:53,  1.89it/s]\u001B[A\n",
      "  3%|▎         | 297/10849 [02:38<1:32:14,  1.91it/s]\u001B[A\n",
      "  3%|▎         | 298/10849 [02:39<1:30:46,  1.94it/s]\u001B[A\n",
      "  3%|▎         | 299/10849 [02:39<1:28:23,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 300/10849 [02:40<1:28:45,  1.98it/s]\u001B[A\n",
      "  3%|▎         | 301/10849 [02:40<1:28:07,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 302/10849 [02:41<1:28:28,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 303/10849 [02:41<1:30:01,  1.95it/s]\u001B[A\n",
      "  3%|▎         | 304/10849 [02:42<1:31:03,  1.93it/s]\u001B[A\n",
      "  3%|▎         | 305/10849 [02:42<1:31:28,  1.92it/s]\u001B[A\n",
      "  3%|▎         | 306/10849 [02:43<1:30:32,  1.94it/s]\u001B[A\n",
      "  3%|▎         | 307/10849 [02:43<1:31:50,  1.91it/s]\u001B[A\n",
      "  3%|▎         | 308/10849 [02:44<1:33:12,  1.88it/s]\u001B[A\n",
      "  3%|▎         | 309/10849 [02:44<1:30:50,  1.93it/s]\u001B[A\n",
      "  3%|▎         | 310/10849 [02:45<1:29:46,  1.96it/s]\u001B[A\n",
      "  3%|▎         | 311/10849 [02:45<1:30:22,  1.94it/s]\u001B[A\n",
      "  3%|▎         | 312/10849 [02:46<1:28:32,  1.98it/s]\u001B[A\n",
      "  3%|▎         | 313/10849 [02:46<1:28:18,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 314/10849 [02:47<1:27:18,  2.01it/s]\u001B[A\n",
      "  3%|▎         | 315/10849 [02:47<1:29:23,  1.96it/s]\u001B[A\n",
      "  3%|▎         | 316/10849 [02:48<1:29:28,  1.96it/s]\u001B[A\n",
      "  3%|▎         | 317/10849 [02:48<1:29:03,  1.97it/s]\u001B[A\n",
      "  3%|▎         | 318/10849 [02:49<1:27:52,  2.00it/s]\u001B[A\n",
      "  3%|▎         | 319/10849 [02:49<1:27:05,  2.02it/s]\u001B[A\n",
      "  3%|▎         | 320/10849 [02:50<1:27:48,  2.00it/s]\u001B[A\n",
      "  3%|▎         | 321/10849 [02:50<1:27:40,  2.00it/s]\u001B[A\n",
      "  3%|▎         | 322/10849 [02:51<1:27:09,  2.01it/s]\u001B[A\n",
      "  3%|▎         | 323/10849 [02:51<1:27:05,  2.01it/s]\u001B[A\n",
      "  3%|▎         | 324/10849 [02:52<1:26:32,  2.03it/s]\u001B[A\n",
      "  3%|▎         | 325/10849 [02:52<1:24:21,  2.08it/s]\u001B[A\n",
      "  3%|▎         | 326/10849 [02:53<1:24:52,  2.07it/s]\u001B[A\n",
      "  3%|▎         | 327/10849 [02:53<1:26:23,  2.03it/s]\u001B[A\n",
      "  3%|▎         | 328/10849 [02:54<1:25:43,  2.05it/s]\u001B[A\n",
      "  3%|▎         | 329/10849 [02:54<1:26:08,  2.04it/s]\u001B[A\n",
      "  3%|▎         | 330/10849 [02:55<1:25:22,  2.05it/s]\u001B[A\n",
      "  3%|▎         | 331/10849 [02:55<1:26:34,  2.02it/s]\u001B[A\n",
      "  3%|▎         | 332/10849 [02:56<1:26:09,  2.03it/s]\u001B[A\n",
      "  3%|▎         | 333/10849 [02:56<1:26:45,  2.02it/s]\u001B[A\n",
      "  3%|▎         | 334/10849 [02:57<1:26:06,  2.04it/s]\u001B[A\n",
      "  3%|▎         | 335/10849 [02:57<1:24:54,  2.06it/s]\u001B[A\n",
      "  3%|▎         | 336/10849 [02:58<1:26:27,  2.03it/s]\u001B[A\n",
      "  3%|▎         | 337/10849 [02:58<1:27:34,  2.00it/s]\u001B[A\n",
      "  3%|▎         | 338/10849 [02:59<1:33:02,  1.88it/s]\u001B[A\n",
      "  3%|▎         | 339/10849 [02:59<1:32:17,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 340/10849 [03:00<1:31:57,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 341/10849 [03:01<1:41:08,  1.73it/s]\u001B[A\n",
      "  3%|▎         | 342/10849 [03:01<1:48:56,  1.61it/s]\u001B[A\n",
      "  3%|▎         | 343/10849 [03:02<1:49:33,  1.60it/s]\u001B[A\n",
      "  3%|▎         | 344/10849 [03:03<1:51:11,  1.57it/s]\u001B[A\n",
      "  3%|▎         | 345/10849 [03:03<1:44:58,  1.67it/s]\u001B[A\n",
      "  3%|▎         | 346/10849 [03:04<1:41:15,  1.73it/s]\u001B[A\n",
      "  3%|▎         | 347/10849 [03:04<1:36:42,  1.81it/s]\u001B[A\n",
      "  3%|▎         | 348/10849 [03:05<1:33:21,  1.87it/s]\u001B[A\n",
      "  3%|▎         | 349/10849 [03:05<1:32:04,  1.90it/s]\u001B[A\n",
      "  3%|▎         | 350/10849 [03:06<1:30:38,  1.93it/s]\u001B[A\n",
      "  3%|▎         | 351/10849 [03:06<1:30:18,  1.94it/s]\u001B[A\n",
      "  3%|▎         | 352/10849 [03:07<1:28:05,  1.99it/s]\u001B[A\n",
      "  3%|▎         | 353/10849 [03:07<1:36:24,  1.81it/s]\u001B[A\n",
      "  3%|▎         | 354/10849 [03:08<1:38:57,  1.77it/s]\u001B[A\n",
      "  3%|▎         | 355/10849 [03:09<1:53:26,  1.54it/s]\u001B[A\n",
      "  3%|▎         | 356/10849 [03:09<1:46:03,  1.65it/s]\u001B[A\n",
      "  3%|▎         | 357/10849 [03:10<1:39:02,  1.77it/s]\u001B[A\n",
      "  3%|▎         | 358/10849 [03:10<1:38:01,  1.78it/s]\u001B[A\n",
      "  3%|▎         | 359/10849 [03:11<1:35:40,  1.83it/s]\u001B[A\n",
      "  3%|▎         | 360/10849 [03:11<1:33:00,  1.88it/s]\u001B[A\n",
      "  3%|▎         | 361/10849 [03:12<1:31:31,  1.91it/s]\u001B[A\n",
      "  3%|▎         | 362/10849 [03:12<1:29:39,  1.95it/s]\u001B[A\n",
      "  3%|▎         | 363/10849 [03:13<1:28:09,  1.98it/s]\u001B[A\n",
      "  3%|▎         | 364/10849 [03:13<1:28:45,  1.97it/s]\u001B[A\n",
      "  3%|▎         | 365/10849 [03:14<1:27:07,  2.01it/s]\u001B[A\n",
      "  3%|▎         | 366/10849 [03:14<1:27:24,  2.00it/s]\u001B[A\n",
      "  3%|▎         | 367/10849 [03:15<1:25:46,  2.04it/s]\u001B[A\n",
      "  3%|▎         | 368/10849 [03:15<1:24:55,  2.06it/s]\u001B[A\n",
      "  3%|▎         | 369/10849 [03:16<1:24:32,  2.07it/s]\u001B[A\n",
      "  3%|▎         | 370/10849 [03:16<1:25:00,  2.05it/s]\u001B[A\n",
      "  3%|▎         | 371/10849 [03:17<1:25:16,  2.05it/s]\u001B[A\n",
      "  3%|▎         | 372/10849 [03:17<1:24:52,  2.06it/s]\u001B[A\n",
      "  3%|▎         | 373/10849 [03:18<1:24:33,  2.06it/s]\u001B[A\n",
      "  3%|▎         | 374/10849 [03:18<1:24:47,  2.06it/s]\u001B[A\n",
      "  3%|▎         | 375/10849 [03:19<1:24:19,  2.07it/s]\u001B[A\n",
      "  3%|▎         | 376/10849 [03:19<1:24:28,  2.07it/s]\u001B[A\n",
      "  3%|▎         | 377/10849 [03:20<1:26:30,  2.02it/s]\u001B[A\n",
      "  3%|▎         | 378/10849 [03:20<1:26:09,  2.03it/s]\u001B[A\n",
      "  3%|▎         | 379/10849 [03:21<1:23:41,  2.08it/s]\u001B[A\n",
      "  4%|▎         | 380/10849 [03:21<1:23:42,  2.08it/s]\u001B[A\n",
      "  4%|▎         | 381/10849 [03:22<1:26:21,  2.02it/s]\u001B[A\n",
      "  4%|▎         | 382/10849 [03:22<1:28:42,  1.97it/s]\u001B[A\n",
      "  4%|▎         | 383/10849 [03:23<1:28:52,  1.96it/s]\u001B[A\n",
      "  4%|▎         | 384/10849 [03:23<1:28:50,  1.96it/s]\u001B[A\n",
      "  4%|▎         | 385/10849 [03:24<1:29:29,  1.95it/s]\u001B[A\n",
      "  4%|▎         | 386/10849 [03:25<1:32:45,  1.88it/s]\u001B[A\n",
      "  0%|          | 0/10 [03:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     19\u001B[0m inputs \u001B[38;5;241m=\u001B[39m extractor(images\u001B[38;5;241m=\u001B[39mimage, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 20\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     22\u001B[0m one_hot \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m21\u001B[39m)\n\u001B[0;32m     23\u001B[0m one_hot[label] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\transformers\\models\\beit\\modeling_beit.py:869\u001B[0m, in \u001B[0;36mBeitForImageClassification.forward\u001B[1;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    863\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m    864\u001B[0m \u001B[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m    865\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m    866\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m    867\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    868\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m--> 869\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mpooler_output \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;28;01melse\u001B[39;00m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    879\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(pooled_output)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\transformers\\models\\beit\\modeling_beit.py:684\u001B[0m, in \u001B[0;36mBeitModel.forward\u001B[1;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    680\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m    682\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(pixel_values, bool_masked_pos)\n\u001B[1;32m--> 684\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    692\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm(sequence_output)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\transformers\\models\\beit\\modeling_beit.py:529\u001B[0m, in \u001B[0;36mBeitEncoder.forward\u001B[1;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    525\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    526\u001B[0m     relative_position_bias \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    527\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelative_position_bias() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelative_position_bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    528\u001B[0m     )\n\u001B[1;32m--> 529\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrelative_position_bias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\transformers\\models\\beit\\modeling_beit.py:423\u001B[0m, in \u001B[0;36mBeitLayer.forward\u001B[1;34m(self, hidden_states, head_mask, output_attentions, relative_position_bias)\u001B[0m\n\u001B[0;32m    420\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(layer_output)\n\u001B[0;32m    421\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(layer_output)\n\u001B[1;32m--> 423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlambda_2\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    424\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlambda_2 \u001B[38;5;241m*\u001B[39m layer_output\n\u001B[0;32m    426\u001B[0m \u001B[38;5;66;03m# second residual connection\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\orletaradzynpodlaski-Fb3ihLOU-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1601\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_backward_pre_hooks\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[0;32m   1599\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m-> 1601\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModule\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m   1602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[0;32m   1603\u001B[0m         _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# trening głowicy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss = 0\n",
    "    for data in tqdm(image_data_set):\n",
    "        image, label = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        inputs = extractor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "        one_hot = torch.zeros(21)\n",
    "        one_hot[label] = 1\n",
    "        loss = criterion(outputs, one_hot.reshape(outputs.shape))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    al = running_loss / len(image_data_set)\n",
    "    losses.append(al)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:23:56.903813893Z",
     "start_time": "2023-05-18T16:23:50.508243268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m inputs \u001B[38;5;241m=\u001B[39m extractor(images\u001B[38;5;241m=\u001B[39mimage, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Użyj modelu do przewidywania klasy\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Przetwórz logity na prawdopodobieństwa\u001B[39;00m\n\u001B[1;32m      9\u001B[0m probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:1205\u001B[0m, in \u001B[0;36mSwinForImageClassification.forward\u001B[0;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1197\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1199\u001B[0m \u001B[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1203\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1205\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mswin\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1211\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1213\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   1215\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(pooled_output)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:1012\u001B[0m, in \u001B[0;36mSwinModel.forward\u001B[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1008\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdepths))\n\u001B[1;32m   1010\u001B[0m embedding_output, input_dimensions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(pixel_values, bool_masked_pos\u001B[38;5;241m=\u001B[39mbool_masked_pos)\n\u001B[0;32m-> 1012\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1022\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm(sequence_output)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:839\u001B[0m, in \u001B[0;36mSwinEncoder.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001B[0m\n\u001B[1;32m    835\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    836\u001B[0m         create_custom_forward(layer_module), hidden_states, input_dimensions, layer_head_mask\n\u001B[1;32m    837\u001B[0m     )\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 839\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malways_partition\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    843\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    844\u001B[0m hidden_states_before_downsampling \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:757\u001B[0m, in \u001B[0;36mSwinStage.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001B[0m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, layer_module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks):\n\u001B[1;32m    755\u001B[0m     layer_head_mask \u001B[38;5;241m=\u001B[39m head_mask[i] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malways_partition\u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    761\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    763\u001B[0m hidden_states_before_downsampling \u001B[38;5;241m=\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:713\u001B[0m, in \u001B[0;36mSwinLayer.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001B[0m\n\u001B[1;32m    711\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm_after(hidden_states)\n\u001B[1;32m    712\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(layer_output)\n\u001B[0;32m--> 713\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    715\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m (layer_output, attention_outputs[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m output_attentions \u001B[38;5;28;01melse\u001B[39;00m (layer_output,)\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m layer_outputs\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:591\u001B[0m, in \u001B[0;36mSwinOutput.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 591\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    592\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[1;32m    593\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for image, label in image_data_set:\n",
    "    # Pextractor\n",
    "    inputs = extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # inferencja\n",
    "    logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # klasfikacja\n",
    "    predicted_class = torch.argmax(probs).item()\n",
    "\n",
    "    print(\"Przewidywana klasa:\", predicted_class, \"Prawdziwa klasa:\", label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

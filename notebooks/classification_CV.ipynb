{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:22:40.359003455Z",
     "start_time": "2023-05-18T16:22:20.804081362Z"
    }
   },
   "outputs": [],
   "source": [
    "# biblioteki\n",
    "from src.dataclass import TextDataSet, ImageDataSet\n",
    "from transformers import ViTImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:22:40.424715643Z",
     "start_time": "2023-05-18T16:22:40.363869897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Å‚adowanie danych\n",
    "image_data_set = ImageDataSet('../datasets/train_set')\n",
    "ImageDataSet.use_rgb(image_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:32:32.033907534Z",
     "start_time": "2023-05-18T16:32:29.993183461Z"
    }
   },
   "outputs": [],
   "source": [
    "# model z hugingface\n",
    "extractor = ViTImageProcessor.from_pretrained(\"marvind434/swin-tiny-patch4-window7-224-finetuned-eurosat\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"marvind434/swin-tiny-patch4-window7-224-finetuned-eurosat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinForImageClassification(\n",
      "  (swin): SwinModel(\n",
      "    (embeddings): SwinEmbeddings(\n",
      "      (patch_embeddings): SwinPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      )\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): SwinEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0-1): 2 x SwinLayer(\n",
      "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0-1): 2 x SwinLayer(\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0-5): 6 x SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0-1): 2 x SwinLayer(\n",
      "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:33:37.330887636Z",
     "start_time": "2023-05-18T16:33:37.264472316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:23:56.903813893Z",
     "start_time": "2023-05-18T16:23:50.508243268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 1 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n",
      "Przewidywana klasa: 0 Prawdziwa klasa: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m inputs \u001B[38;5;241m=\u001B[39m extractor(images\u001B[38;5;241m=\u001B[39mimage, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# UÅ¼yj modelu do przewidywania klasy\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# PrzetwÃ³rz logity na prawdopodobieÅ„stwa\u001B[39;00m\n\u001B[1;32m      9\u001B[0m probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:1205\u001B[0m, in \u001B[0;36mSwinForImageClassification.forward\u001B[0;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1197\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1199\u001B[0m \u001B[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1203\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1205\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mswin\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1211\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1213\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   1215\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(pooled_output)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:1012\u001B[0m, in \u001B[0;36mSwinModel.forward\u001B[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1008\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdepths))\n\u001B[1;32m   1010\u001B[0m embedding_output, input_dimensions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(pixel_values, bool_masked_pos\u001B[38;5;241m=\u001B[39mbool_masked_pos)\n\u001B[0;32m-> 1012\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1022\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm(sequence_output)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:839\u001B[0m, in \u001B[0;36mSwinEncoder.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001B[0m\n\u001B[1;32m    835\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    836\u001B[0m         create_custom_forward(layer_module), hidden_states, input_dimensions, layer_head_mask\n\u001B[1;32m    837\u001B[0m     )\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 839\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malways_partition\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    843\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    844\u001B[0m hidden_states_before_downsampling \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:757\u001B[0m, in \u001B[0;36mSwinStage.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001B[0m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, layer_module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks):\n\u001B[1;32m    755\u001B[0m     layer_head_mask \u001B[38;5;241m=\u001B[39m head_mask[i] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dimensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malways_partition\u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    761\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    763\u001B[0m hidden_states_before_downsampling \u001B[38;5;241m=\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:713\u001B[0m, in \u001B[0;36mSwinLayer.forward\u001B[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001B[0m\n\u001B[1;32m    711\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm_after(hidden_states)\n\u001B[1;32m    712\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(layer_output)\n\u001B[0;32m--> 713\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    715\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m (layer_output, attention_outputs[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m output_attentions \u001B[38;5;28;01melse\u001B[39;00m (layer_output,)\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m layer_outputs\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:591\u001B[0m, in \u001B[0;36mSwinOutput.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 591\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    592\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[1;32m    593\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/orletaradzynpodlaski-ex4sxb3S-py3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for image, label in image_data_set:\n",
    "    # Pextractor\n",
    "    inputs = extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # inferencja\n",
    "    logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # klasfikacja\n",
    "    predicted_class = torch.argmax(probs).item()\n",
    "\n",
    "    print(\"Przewidywana klasa:\", predicted_class, \"Prawdziwa klasa:\", label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
